<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Abu Adnan Sadi </title> <meta name="author" content="Abu Adnan Sadi"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adnan-sadi.github.io/publications/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Abu Adnan</span> Sadi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/add_preview-480.webp 480w,/assets/img/publication_preview/add_preview-800.webp 800w,/assets/img/publication_preview/add_preview-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/add_preview.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="add_preview.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sadi2024automatic" class="col-sm-8"> <div class="title">Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification</div> <div class="author"> Abu Adnan Sadi, Mohammad Ashrafuzzaman Khan, and Lubaba Binte Saber </div> <div class="periodical"> <em>arXiv preprint arXiv:2408.15827</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/add_preprint.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://huggingface.co/spaces/AdnanSadi/Differential-Diagnosis-Tool" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Demo</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=jNtX0U4AAAAJ&amp;citation_for_view=jNtX0U4AAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>As the field of artificial intelligence progresses, assistive technologies are becoming more widely used across all industries. The healthcare industry is no different, with numerous studies being done to develop assistive tools for healthcare professionals. Automatic diagnostic systems are one such beneficial tool that can assist with a variety of tasks, including collecting patient information, analyzing test results, and diagnosing patients. However, the idea of developing systems that can provide a differential diagnosis has been largely overlooked in most of these research studies. In this study, we propose a transformer-based approach for providing differential diagnoses based on a patient’s age, sex, medical history, and symptoms. We use the DDXPlus dataset, which provides differential diagnosis information for patients based on 49 disease types. Firstly, we propose a method to process the tabular patient data from the dataset and engineer them into patient reports to make them suitable for our research. In addition, we introduce two data modification modules to diversify the training data and consequently improve the robustness of the models. We approach the task as a multi-label classification problem and conduct extensive experiments using four transformer models. All the models displayed promising results by achieving over 97% F1 score on the held-out test set. Moreover, we design additional behavioral tests to get a broader understanding of the models. In particular, for one of our test cases, we prepared a custom test set of 100 samples with the assistance of a doctor. The results on the custom set showed that our proposed data modification modules improved the model’s generalization capabilities. We hope our findings will provide future researchers with valuable insights and inspire them to develop reliable systems for automatic differential diagnosis.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sadi2024automatic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic Differential Diagnosis using Transformer-Based Multi-Label Sequence Classification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sadi, Abu Adnan and Khan, Mohammad Ashrafuzzaman and Saber, Lubaba Binte}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2408.15827}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/arXiv.2408.15827}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{2osOgNQ5qMEC}</span><span class="p">,</span>
  <span class="na">demo</span> <span class="p">=</span> <span class="s">{https://huggingface.co/spaces/AdnanSadi/Differential-Diagnosis-Tool}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/YOLO-480.webp 480w,/assets/img/publication_preview/YOLO-800.webp 800w,/assets/img/publication_preview/YOLO-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/YOLO.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="YOLO.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="sadi2024comparative" class="col-sm-8"> <div class="title">A Comparative Study on Plant Diseases Using Object Detection Models</div> <div class="author"> Abu Adnan Sadi, Ziaul Hossain, Ashfaq Uddin Ahmed, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Md Tazin Morshed Shad' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Science and Information Conference</em> . The <em>peer-reviewed and final</em> version of the paper is available <a href="https://doi.org/10.1007/978-3-031-62269-4_29" rel="external nofollow noopener" target="_blank">here</a> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/A%20Comparative%20Study%20on%20Plant%20Diseases.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/Adnan-Sadi/Plant-Disease-Detection-YOLO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=jNtX0U4AAAAJ&amp;citation_for_view=jNtX0U4AAAAJ:9yKSN-GCB0IC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Plant diseases are the most widespread and significant hazard to ‘Precision Agriculture’. With early detection and analysis of diseases, the successful yield of cultivation can be increased; therefore, this process is regarded as a critical event. Unfortunately, manual observation-based detection method is error-prone, hard, and costly. Automation in identifying plant diseases is extremely beneficial because it saves time and manpower. Applying a neural network-based solution can detect disease symptoms at an early stage and facilitate the process of taking preventive or reactive measures. There have been various deep learning-based solutions, which were developed using lengthy training/testing cycles with large datasets. This study aims to investigate the suitability of computer vision-based approaches for this purpose. A comparative study has been performed using recently proposed object detection models such as YOLOv5, YOLOX, Scaled Yolov4, and SSD. A tailored version of the “PlantVillage” and “PlantDoc” datasets was used in the Indian sub-continent context, which included plant disease classes related to Potato, Corn, and Tomato plants. This study provides a detailed comparison between these object detection models and summarizes the suitability of these models for different cases. This paper can be useful for prospective researchers to decide which object detection models could be used for a specific scenario of Plant Disease Detection.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sadi2024comparative</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Comparative Study on Plant Diseases Using Object Detection Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sadi, Abu Adnan and Hossain, Ziaul and Ahmed, Ashfaq Uddin and Shad, Md Tazin Morshed}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Science and Information Conference}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{419--438}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-031-62269-4_29}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{9yKSN-GCB0IC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/vispol2023_preview-480.webp 480w,/assets/img/publication_preview/vispol2023_preview-800.webp 800w,/assets/img/publication_preview/vispol2023_preview-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/vispol2023_preview.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vispol2023_preview.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vispol2023" class="col-sm-8"> <div class="title">An end-to-end pollution analysis and detection system using artificial intelligence and object detection algorithms</div> <div class="author"> Md Yearat Hossain, Ifran Rahman Nijhum, Md Tazin Morshed Shad, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Abu Adnan Sadi, Md Mahmudul Kabir Peyal, Rashedur M Rahman' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Decision Analytics Journal</em>. <em>Dataset</em> can be <a href="https://www.kaggle.com/datasets/yearathossain/visual-pollution-dhaka-streets" rel="external nofollow noopener" target="_blank">found here</a> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Visual_pollution_paper_2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=jNtX0U4AAAAJ&amp;citation_for_view=jNtX0U4AAAAJ:u5HHmVD_uO8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-7-4285F4?logo=googlescholar&amp;labelColor=beige" alt="7 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Environmental pollution is generally a by-product of various human activities. Researchers have studied the dangers and harmful effects of pollutants and environmental pollution for centuries, and many necessary steps have been taken. Modern solutions are being constantly developed to tackle these issues efficiently. Visual pollution analysis and detection is a relatively less studied subject, even though it significantly impacts our daily lives. Building automatic pollution or pollutants detection systems has become increasingly popular due to the modern development of advanced artificial intelligence systems. Although some advances have been made, automated pollution detection is not well-researched or fully understood. This study demonstrates how various object detection models could identify such environmental pollutants and how end-to-end applications can analyze the findings. We trained our dataset on three popular object detection models, YOLOv5, Faster R-CNN (Region-based Convolutional Neural Network), and EfficientDet, and compared their performances. The best Mean Average Precision (mAP) score of 0.85 was achieved by the You Only Look Once (YOLOv5) model using its inbuilt augmentation techniques. Then we built a minimal Android application, using which volunteers or authorities could capture and send images along with their Global Positioning System (GPS) coordinates that might contain visual pollutants. These images and coordinates are stored in the cloud and later used by our local server. The local server utilizes the best-trained visual pollution detection model. It generates heat maps of particular locations, visualizing the condition of visual pollution based on the data stored in the cloud. Along with the heat map, our analysis system provides visual analytics like bar charts and pie charts to summarize a region’s condition. In addition, we used Active Learning and Incremental Learning methods to utilize the newly collected dataset by building a semi-autonomous annotation and model upgrading system. This also addresses the data scarcity problem associated with further research on visual pollution.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">vispol2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An end-to-end pollution analysis and detection system using artificial intelligence and object detection algorithms}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hossain, Md Yearat and Nijhum, Ifran Rahman and Shad, Md Tazin Morshed and Sadi, Abu Adnan and Peyal, Md Mahmudul Kabir and Rahman, Rashedur M}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Decision Analytics Journal}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100283}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.dajour.2023.100283}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{u5HHmVD_uO8C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/lmfloss_preview-480.webp 480w,/assets/img/publication_preview/lmfloss_preview-800.webp 800w,/assets/img/publication_preview/lmfloss_preview-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/lmfloss_preview.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lmfloss_preview.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="LMFloss2022" class="col-sm-8"> <div class="title">LMFLOSS: A Hybrid Loss For Imbalanced Medical Image Classification</div> <div class="author"> Abu Adnan Sadi, Labib Chowdhury, Nusrat Jahan, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Mohammad Newaz Sharif Rafi, Radeya Chowdhury, Faisal Ahamed Khan, Nabeel Mohammed' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2212.12741</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/LMFLoss_Arxiv.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/Adnan-Sadi/LMFLOSS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=jNtX0U4AAAAJ&amp;citation_for_view=jNtX0U4AAAAJ:u-x6o8ySG0sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-14-4285F4?logo=googlescholar&amp;labelColor=beige" alt="14 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Automatic medical image classification is a very important field where the use of AI has the potential to have a real social impact. However, there are still many challenges that act as obstacles to making practically effective solutions. One of those is the fact that most of the medical imaging datasets have a class imbalance problem. This leads to the fact that existing AI techniques, particularly neural network-based deep-learning methodologies, often perform poorly in such scenarios. Thus this makes this area an interesting and active research focus for researchers. In this study, we propose a novel loss function to train neural network models to mitigate this critical issue in this important field. Through rigorous experiments on three independently collected datasets of three different medical imaging domains, we empirically show that our proposed loss function consistently performs well with an improvement between 2%-10% macro f1 when compared to the baseline models. We hope that our work will precipitate new research toward a more generalized approach to medical image classification.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">LMFloss2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{LMFLOSS: A Hybrid Loss For Imbalanced Medical Image Classification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sadi, Abu Adnan and Chowdhury, Labib and Jahan, Nusrat and Rafi, Mohammad Newaz Sharif and Chowdhury, Radeya and Khan, Faisal Ahamed and Mohammed, Nabeel}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2212.12741}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/arXiv.2212.12741}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{u-x6o8ySG0sC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/vispol2021_preview-480.webp 480w,/assets/img/publication_preview/vispol2021_preview-800.webp 800w,/assets/img/publication_preview/vispol2021_preview-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/vispol2021_preview.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vispol2021_preview.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vispol2021" class="col-sm-8"> <div class="title">Visual Pollution Detection Using Google Street View and YOLO</div> <div class="author"> Md Yearat Hossain, Ifran Rahman Nijhum, Abu Adnan Sadi, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Md Tazin Morshed Shad, Rashedur M Rahman' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In 2021 IEEE 12th Annual Ubiquitous Computing, Electronics &amp; Mobile Communication Conference (UEMCON)</em> . <em>Dataset</em> can be <a href="https://www.kaggle.com/datasets/yearathossain/visual-pollution-dhaka-streets" rel="external nofollow noopener" target="_blank">found here</a> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Visual_pollution_paper_2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=jNtX0U4AAAAJ&amp;citation_for_view=jNtX0U4AAAAJ:d1gkVwhDpl0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-8-4285F4?logo=googlescholar&amp;labelColor=beige" alt="8 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In recent years, visual pollution has become a major concern in rapidly rising cities. This research deals with detecting visual pollutants from the street images collected using Google Street View. For this experiment, we chose the streets of Dhaka, the capital city of Bangladesh, to build our image dataset, mainly because Dhaka was ranked recently as one of the most polluted cities in the world. However, the methods shown in this study can be applied to images of any city around the world and would produce close to a similar output. Throughout this study, we tried to portray the possible utilisation of Google Street View in building datasets and how this data can be used to solve environmental pollution with the help of deep learning. The image dataset was created manually by taking screenshots from various angles of every street view with visual pollutants in the frame. The images were then manually annotated using CVAT and were fed into the model for training. For the detection, we have used the object detection model YOLOv5 to detect all the visual pollutants present in the image. Finally, we evaluated the results achieved from this study and gave direction of using the outcome from this study in different domains.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">vispol2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Visual Pollution Detection Using Google Street View and YOLO}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hossain, Md Yearat and Nijhum, Ifran Rahman and Sadi, Abu Adnan and Shad, Md Tazin Morshed and Rahman, Rashedur M}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE 12th Annual Ubiquitous Computing, Electronics \&amp; Mobile Communication Conference (UEMCON)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{0433--0440}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/UEMCON53757.2021.9666654}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{d1gkVwhDpl0C}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?fa0110e8b42cec56ce96d912fd4bde74"></script> <script>addBackToTop();</script> </body> </html>